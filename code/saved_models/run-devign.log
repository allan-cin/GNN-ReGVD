/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
07/31/2023 18:44:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
07/31/2023 18:44:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, alpha_weight=1.0, att_op='mul', block_size=400, cache_dir='', config_name='', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_test=True, do_train=True, epoch=100, eval_all_checkpoints=False, eval_batch_size=128, eval_data_file='../dataset/valid.jsonl', evaluate_during_training=True, feature_dim_size=768, format='uni', fp16=False, fp16_opt_level='O1', gnn='ReGCN', gradient_accumulation_steps=1, hidden_size=128, learning_rate=0.0005, local_rank=-1, log_neptune=False, logging_steps=50, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model='devign', model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', n_gpu=1, no_cuda=False, num_GNN_layers=2, num_classes=2, num_train_epochs=1.0, output_dir='./saved_models/devign', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=128, per_gpu_train_batch_size=128, remove_residual=False, save_steps=50, save_total_limit=None, seed=123456, server_ip='', server_port='', start_epoch=0, start_step=0, test_data_file='../dataset/test.jsonl', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=128, train_data_file='../dataset/train.jsonl', training_percent=1.0, warmup_steps=0, weight_decay=0.0, window_size=5)
07/31/2023 18:45:18 - INFO - __main__ -   *** Total Sample ***
07/31/2023 18:45:18 - INFO - __main__ -         Total: 21854    selected: 21854 percent: 1.0
07/31/2023 18:45:18 - INFO - __main__ -   *** Sample ***
07/31/2023 18:45:18 - INFO - __main__ -   Total sample
07/31/2023 18:45:18 - INFO - __main__ -   idx: 0
07/31/2023 18:45:18 - INFO - __main__ -   label: 0
07/31/2023 18:45:18 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_av', '_', 'cold', '_int', '_v', 'd', 'ade', 'c', '_', 'init', '(', 'AV', 'Cod', 'ec', 'Context', '_*', 'av', 'ctx', ')', '_{', '_V', 'D', 'AD', 'ec', 'oder', 'Context', '_*', 'ctx', '_=', '_av', 'ctx', '->', 'priv', '_', 'data', ';', '_struct', '_v', 'da', '_', 'context', '_*', 'v', 'da', '_', 'ctx', '_=', '_&', 'ctx', '->', 'v', 'da', '_', 'ctx', ';', '_OS', 'Status', '_status', ';', '_int', '_ret', ';', '_c', 'tx', '->', 'h', '264', '_', 'initialized', '_=', '_0', ';', '_/*', '_init', '_p', 'ix', '_', 'fm', 'ts', '_of', '_codec', '_*/', '_if', '_(!', 'ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', ')', '_{', '_if', '_(', 'k', 'C', 'FC', 'ore', 'Found', 'ation', 'Version', 'Number', '_<', '_k', 'C', 'FC', 'ore', 'Found', 'ation', 'Version', 'Number', '10', '_', '7', ')', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', '_=', '_v', 'da', '_', 'p', 'ix', 'fm', 'ts', '_', 'pri', 'or', '_', '10', '_', '7', ';', '_else', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', '_=', '_v', 'da', '_', 'p', 'ix', 'fm', 'ts', ';', '_}', '_/*', '_init', '_v', 'da', '_*/', '_mem', 'set', '(', 'v', 'da', '_', 'ctx', ',', '_0', ',', '_sizeof', '(', 'struct', '_v', 'da', '_', 'context', '));', '_v', 'da', '_', 'ctx', '->', 'width', '_=', '_av', 'ctx', '->', 'width', ';', '_v', 'da', '_', 'ctx', '->', 'height', '_=', '_av', 'ctx', '->', 'height', ';', '_v', 'da', '_', 'ctx', '->', 'format', '_=', "_'", 'av', 'c', '1', "';", '_v', 'da', '_', 'ctx', '->', 'use', '_', 'sync', '_', 'dec', 'oding', '_=', '_1', ';', '_v', 'da', '_', 'ctx', '->', 'use', '_', 'ref', '_', 'buffer', '_=', '_1', ';', '_c', 'tx', '->', 'p', 'ix', '_', 'f', 'mt', '_=', '_av', 'ctx', '->', 'get', '_', 'format', '(', 'av', 'ctx', ',', '_av', 'ctx', '->', 'cod', 'ec', '->', 'p', 'ix', '_', 'fm', 'ts', ');', '_switch', '_(', 'ctx', '->', 'p', 'ix', '_', 'f', 'mt', ')', '_{', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'U', 'Y', 'V', 'Y', '422', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'p', 'ix', '_', 'f', 'mt', '_', 'type', '_=', "_'", '2', 'v', 'uy', "';", '_break', ';', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'Y', 'U', 'Y', 'V', '422', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'p', 'ix', '_', 'f', 'mt', '_', 'type', '_=', "_'", 'yu', 'vs', "';", '_break', ';', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'NV', '12', ':', '</s>']
07/31/2023 18:45:18 - INFO - __main__ -   input_ids: 0 42653 6402 1215 33912 6979 748 417 1829 438 1215 25153 1640 10612 47436 3204 48522 1009 1469 49575 43 25522 468 495 2606 3204 15362 48522 1009 49575 5457 6402 49575 46613 25943 1215 23687 131 29916 748 6106 1215 46796 1009 705 6106 1215 49575 5457 359 49575 46613 705 6106 1215 49575 131 8192 47731 2194 131 6979 5494 131 740 43820 46613 298 29137 1215 49722 5457 321 131 48565 45511 181 3181 1215 40523 1872 9 45797 48404 114 48209 3145 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 43 25522 114 36 330 347 5268 1688 29991 1258 47322 43623 28696 449 347 5268 1688 29991 1258 47322 43623 698 1215 406 43 48400 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 5457 748 6106 1215 642 3181 40523 1872 1215 13718 368 1215 698 1215 406 131 1493 48400 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 5457 748 6106 1215 642 3181 40523 1872 131 35524 48565 45511 748 6106 48404 26012 8738 1640 705 6106 1215 49575 6 321 6 49907 1640 25384 748 6106 1215 46796 48749 748 6106 1215 49575 46613 36097 5457 6402 49575 46613 36097 131 748 6106 1215 49575 46613 37009 5457 6402 49575 46613 37009 131 748 6106 1215 49575 46613 34609 5457 128 1469 438 134 23500 748 6106 1215 49575 46613 3698 1215 45176 1215 11127 19519 5457 112 131 748 6106 1215 49575 46613 3698 1215 13043 1215 47438 5457 112 131 740 43820 46613 642 3181 1215 506 16100 5457 6402 49575 46613 6460 1215 34609 1640 1469 49575 6 6402 49575 46613 29659 3204 46613 642 3181 1215 40523 1872 4397 5405 36 49575 46613 642 3181 1215 506 16100 43 25522 403 17307 1215 510 9482 1215 597 11674 1215 791 975 846 975 37319 35 748 6106 1215 49575 46613 38635 1215 642 3181 1215 506 16100 1215 12528 5457 128 176 705 5781 23500 1108 131 403 17307 1215 510 9482 1215 597 11674 1215 975 791 975 846 37319 35 748 6106 1215 49575 46613 38635 1215 642 3181 1215 506 16100 1215 12528 5457 128 29159 15597 23500 1108 131 403 17307 1215 510 9482 1215 597 11674 1215 31668 1092 35 2
07/31/2023 18:45:18 - INFO - __main__ -   *** Sample ***
07/31/2023 18:45:18 - INFO - __main__ -   Total sample
07/31/2023 18:45:18 - INFO - __main__ -   idx: 1
07/31/2023 18:45:18 - INFO - __main__ -   label: 0
07/31/2023 18:45:18 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_int', '_trans', 'code', '(', 'AV', 'Format', 'Context', '_**', 'output', '_', 'files', ',', '_int', '_n', 'b', '_', 'output', '_', 'files', ',', '_Input', 'File', '_*', 'input', '_', 'files', ',', '_int', '_n', 'b', '_', 'input', '_', 'files', ',', '_Stream', 'Map', '_*', 'stream', '_', 'maps', ',', '_int', '_n', 'b', '_', 'stream', '_', 'maps', ')', '_{', '_int', '_ret', '_=', '_0', ',', '_i', ',', '_j', ',', '_k', ',', '_n', ',', '_n', 'b', '_', 'ost', 'ream', 's', '_=', '_0', ',', '_step', ';', '_AV', 'Format', 'Context', '_*', 'is', ',', '_*', 'os', ';', '_AV', 'Cod', 'ec', 'Context', '_*', 'cod', 'ec', ',', '_*', 'ic', 'od', 'ec', ';', '_Output', 'Stream', '_*', 'ost', ',', '_**', 'ost', '_', 'table', '_=', '_NULL', ';', '_Input', 'Stream', '_*', 'ist', ';', '_char', '_error', '[', '1024', '];', '_int', '_key', ';', '_int', '_want', '_', 'sd', 'p', '_=', '_1', ';', '_uint', '8', '_', 't', '_no', '_', 'pack', 'et', '[', 'MAX', '_', 'FIL', 'ES', ']=', '{', '0', '};', '_int', '_no', '_', 'pack', 'et', '_', 'count', '=', '0', ';', '_int', '_n', 'b', '_', 'frame', '_', 'th', 'reshold', '[', 'AV', 'MED', 'IA', '_', 'TYPE', '_', 'NB', ']=', '{', '0', '};', '_int', '_n', 'b', '_', 'stream', 's', '[', 'AV', 'MED', 'IA', '_', 'TYPE', '_', 'NB', ']=', '{', '0', '};', '_if', '_(', 'rate', '_', 'em', 'u', ')', '_for', '_(', 'i', '_=', '_0', ';', '_i', '_<', '_n', 'b', '_', 'input', '_', 'stream', 's', ';', '_i', '++)', '_input', '_', 'stream', 's', '[', 'i', '].', 'start', '_=', '_av', '_', 'get', 'time', '();', '_/*', '_output', '_stream', '_init', '_*/', '_n', 'b', '_', 'ost', 'ream', 's', '_=', '_0', ';', '_for', '(', 'i', '=', '0', ';', 'i', '<', 'nb', '_', 'output', '_', 'files', ';', 'i', '++)', '_{', '_os', '_=', '_output', '_', 'files', '[', 'i', '];', '_if', '_(!', 'os', '->', 'nb', '_', 'stream', 's', '_&&', '_!', '(', 'os', '->', 'o', 'format', '->', 'flags', '_&', '_AV', 'F', 'MT', '_', 'N', 'OST', 'REAM', 'S', '))', '_{', '_av', '_', 'dump', '_', 'format', '(', 'output', '_', 'files', '[', 'i', '],', '_i', ',', '_output', '_', 'files', '[', 'i', ']', '->', 'filename', ',', '_1', ');', '_f', 'printf', '(', 'st', 'der', 'r', ',', '_"', 'Output', '_file', '_#', '%', 'd', '_does', '_not', '_contain', '_any', '_stream', '\\', 'n', '",', '_i', ');', '_ret', '_=', '_A', 'VER', 'ROR', '(', 'E', 'IN', 'VAL', ');', '_goto', '_fail', ';', '_}', '_n', 'b', '_', 'ost', 'ream', 's', '_+=', '_os', '->', 'nb', '_', 'stream', 's', ';', '_}', '_if', '_(', 'nb', '_', 'stream', '_', 'maps', '_>', '_0', '_&&', '_n', 'b', '_', 'stream', '_', 'maps', '_!=', '_n', 'b', '</s>']
07/31/2023 18:45:18 - INFO - __main__ -   input_ids: 0 42653 6979 6214 20414 1640 10612 48587 48522 13540 46234 1215 42018 6 6979 295 428 1215 46234 1215 42018 6 41327 9966 1009 46797 1215 42018 6 6979 295 428 1215 46797 1215 42018 6 16183 41151 1009 8656 1215 44754 6 6979 295 428 1215 8656 1215 44754 43 25522 6979 5494 5457 321 6 939 6 1236 6 449 6 295 6 295 428 1215 2603 26930 29 5457 321 6 1149 131 17307 48587 48522 1009 354 6 1009 366 131 17307 47436 3204 48522 1009 29659 3204 6 1009 636 1630 3204 131 38252 36757 1009 2603 6 13540 2603 1215 14595 5457 48955 131 41327 36757 1009 661 131 16224 5849 10975 47477 44082 6979 762 131 6979 236 1215 28045 642 5457 112 131 49315 398 1215 90 117 1215 12486 594 10975 30187 1215 46008 1723 49659 45152 288 49423 6979 117 1215 12486 594 1215 11432 5214 288 131 6979 295 428 1215 26061 1215 212 45749 10975 10612 32653 2889 1215 48710 1215 20485 49659 45152 288 49423 6979 295 428 1215 8656 29 10975 10612 32653 2889 1215 48710 1215 20485 49659 45152 288 49423 114 36 7954 1215 991 257 43 13 36 118 5457 321 131 939 28696 295 428 1215 46797 1215 8656 29 131 939 49346 8135 1215 8656 29 10975 118 8174 13124 5457 6402 1215 6460 958 47006 48565 4195 4615 45511 48404 295 428 1215 2603 26930 29 5457 321 131 13 1640 118 5214 288 131 118 41552 40460 1215 46234 1215 42018 131 118 49346 25522 11988 5457 4195 1215 42018 10975 118 44082 114 48209 366 46613 40460 1215 8656 29 48200 27785 1640 366 46613 139 34609 46613 46760 359 17307 597 11674 1215 487 13556 28057 104 35122 25522 6402 1215 46593 1215 34609 1640 46234 1215 42018 10975 118 7479 939 6 4195 1215 42018 10975 118 742 46613 49451 6 112 4397 856 49775 1640 620 3624 338 6 22 48293 2870 849 207 417 473 45 5585 143 4615 37457 282 1297 939 4397 5494 5457 83 9847 45055 1640 717 2444 39766 4397 49325 5998 131 35524 295 428 1215 2603 26930 29 49371 11988 46613 40460 1215 8656 29 131 35524 114 36 40460 1215 8656 1215 44754 8061 321 48200 295 428 1215 8656 1215 44754 49333 295 428 2
07/31/2023 18:45:18 - INFO - __main__ -   *** Sample ***
07/31/2023 18:45:18 - INFO - __main__ -   Total sample
07/31/2023 18:45:18 - INFO - __main__ -   idx: 2
07/31/2023 18:45:18 - INFO - __main__ -   label: 0
07/31/2023 18:45:18 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_void', '_v', '4', 'l', '2', '_', 'free', '_', 'buffer', '(', 'void', '_*', 'op', 'aque', ',', '_uint', '8', '_', 't', '_*', 'un', 'used', ')', '_{', '_V', '4', 'L', '2', 'Buffer', '*', '_av', 'buf', '_=', '_opaque', ';', '_V', '4', 'L', '2', 'm', '2', 'm', 'Context', '_*', 's', '_=', '_buf', '_', 'to', '_', 'm', '2', 'm', 'ctx', '(', 'av', 'buf', ');', '_if', '_(', 'atomic', '_', 'f', 'etch', '_', 'sub', '(&', 'av', 'buf', '->', 'context', '_', 'ref', 'count', ',', '_1', ')', '_==', '_1', ')', '_{', '_atomic', '_', 'f', 'etch', '_', 'sub', '_', 'expl', 'icit', '(&', 's', '->', 'ref', 'count', ',', '_1', ',', '_memory', '_', 'order', '_', 'ac', 'q', '_', 'rel', ');', '_if', '_(', 's', '->', 're', 'init', ')', '_{', '_if', '_(!', 'atomic', '_', 'load', '(&', 's', '->', 'ref', 'count', '))', '_sem', '_', 'post', '(&', 's', '->', 'ref', 'sync', ');', '_}', '_else', '_if', '_(', 'av', 'buf', '->', 'context', '->', 'stream', 'on', ')', '_ff', '_', 'v', '4', 'l', '2', '_', 'buffer', '_', 'en', 'queue', '(', 'av', 'buf', ');', '_av', '_', 'buffer', '_', 'un', 'ref', '(&', 'av', 'buf', '->', 'context', '_', 'ref', ');', '_}', '_}', '</s>']
07/31/2023 18:45:18 - INFO - __main__ -   input_ids: 0 42653 13842 748 306 462 176 1215 3743 1215 47438 1640 47908 1009 1517 35485 6 49315 398 1215 90 1009 879 6199 43 25522 468 306 574 176 49334 3226 6402 48939 5457 31861 131 468 306 574 176 119 176 119 48522 1009 29 5457 49125 1215 560 1215 119 176 119 49575 1640 1469 48939 4397 114 36 45826 1215 506 29094 1215 10936 49763 1469 48939 46613 46796 1215 13043 11432 6 112 43 45994 112 43 25522 21495 1215 506 29094 1215 10936 1215 23242 17022 49763 29 46613 13043 11432 6 112 6 3783 1215 10337 1215 1043 1343 1215 5982 4397 114 36 29 46613 241 25153 43 25522 114 48209 45826 1215 16204 49763 29 46613 13043 11432 35122 9031 1215 7049 49763 29 46613 13043 45176 4397 35524 1493 114 36 1469 48939 46613 46796 46613 8656 261 43 48400 1215 705 306 462 176 1215 47438 1215 225 48702 1640 1469 48939 4397 6402 1215 47438 1215 879 13043 49763 1469 48939 46613 46796 1215 13043 4397 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
07/31/2023 18:45:19 - INFO - __main__ -   ***** Running training *****
07/31/2023 18:45:19 - INFO - __main__ -     Num examples = 21854
07/31/2023 18:45:19 - INFO - __main__ -     Num Epochs = 100
07/31/2023 18:45:19 - INFO - __main__ -     Instantaneous batch size per GPU = 128
07/31/2023 18:45:19 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 128
07/31/2023 18:45:19 - INFO - __main__ -     Gradient Accumulation steps = 1
07/31/2023 18:45:19 - INFO - __main__ -     Total optimization steps = 17100
using default unweighted graph
Using devign
07/31/2023 18:59:14 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 18:59:14 - INFO - __main__ -     Num examples = 2732
07/31/2023 18:59:14 - INFO - __main__ -     Batch size = 128
07/31/2023 18:59:47 - INFO - __main__ -     eval_loss = 0.6877
07/31/2023 18:59:47 - INFO - __main__ -     eval_acc = 0.5655
07/31/2023 18:59:47 - INFO - __main__ -     ********************
07/31/2023 18:59:47 - INFO - __main__ -     Best acc:0.5655
07/31/2023 18:59:47 - INFO - __main__ -     ********************
07/31/2023 18:59:49 - INFO - __main__ -   Saving model checkpoint to ./saved_models/devign/checkpoint-best-acc/model.bin
07/31/2023 18:59:49 - INFO - __main__ -   epoch 0 loss 0.69205
07/31/2023 19:11:18 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 19:11:18 - INFO - __main__ -     Num examples = 2732
07/31/2023 19:11:18 - INFO - __main__ -     Batch size = 128
07/31/2023 19:11:52 - INFO - __main__ -     eval_loss = 0.6863
07/31/2023 19:11:52 - INFO - __main__ -     eval_acc = 0.5655
07/31/2023 19:11:52 - INFO - __main__ -   epoch 1 loss 0.69068
07/31/2023 19:21:56 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 19:21:56 - INFO - __main__ -     Num examples = 2732
07/31/2023 19:21:56 - INFO - __main__ -     Batch size = 128
07/31/2023 19:22:30 - INFO - __main__ -     eval_loss = 0.6753
07/31/2023 19:22:30 - INFO - __main__ -     eval_acc = 0.552
07/31/2023 19:22:30 - INFO - __main__ -   epoch 2 loss 0.68438
07/31/2023 19:32:36 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 19:32:36 - INFO - __main__ -     Num examples = 2732
07/31/2023 19:32:36 - INFO - __main__ -     Batch size = 128
07/31/2023 19:33:09 - INFO - __main__ -     eval_loss = 0.6616
07/31/2023 19:33:09 - INFO - __main__ -     eval_acc = 0.582
07/31/2023 19:33:09 - INFO - __main__ -     ********************
07/31/2023 19:33:09 - INFO - __main__ -     Best acc:0.582
07/31/2023 19:33:09 - INFO - __main__ -     ********************
07/31/2023 19:33:10 - INFO - __main__ -   Saving model checkpoint to ./saved_models/devign/checkpoint-best-acc/model.bin
07/31/2023 19:33:10 - INFO - __main__ -   epoch 3 loss 0.6709
07/31/2023 19:45:47 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 19:45:47 - INFO - __main__ -     Num examples = 2732
07/31/2023 19:45:47 - INFO - __main__ -     Batch size = 128
07/31/2023 19:46:18 - INFO - __main__ -     eval_loss = 0.6585
07/31/2023 19:46:18 - INFO - __main__ -     eval_acc = 0.5944
07/31/2023 19:46:18 - INFO - __main__ -     ********************
07/31/2023 19:46:18 - INFO - __main__ -     Best acc:0.5944
07/31/2023 19:46:18 - INFO - __main__ -     ********************
07/31/2023 19:46:19 - INFO - __main__ -   Saving model checkpoint to ./saved_models/devign/checkpoint-best-acc/model.bin
07/31/2023 19:46:19 - INFO - __main__ -   epoch 4 loss 0.65016
07/31/2023 19:55:55 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 19:55:55 - INFO - __main__ -     Num examples = 2732
07/31/2023 19:55:55 - INFO - __main__ -     Batch size = 128
07/31/2023 19:56:26 - INFO - __main__ -     eval_loss = 0.7268
07/31/2023 19:56:26 - INFO - __main__ -     eval_acc = 0.5673
07/31/2023 19:56:26 - INFO - __main__ -   epoch 5 loss 0.6012
07/31/2023 20:06:02 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 20:06:02 - INFO - __main__ -     Num examples = 2732
07/31/2023 20:06:02 - INFO - __main__ -     Batch size = 128
07/31/2023 20:06:34 - INFO - __main__ -     eval_loss = 0.6738
07/31/2023 20:06:34 - INFO - __main__ -     eval_acc = 0.5878
07/31/2023 20:06:34 - INFO - __main__ -   epoch 6 loss 0.53996
07/31/2023 20:20:34 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 20:20:34 - INFO - __main__ -     Num examples = 2732
07/31/2023 20:20:34 - INFO - __main__ -     Batch size = 128
07/31/2023 20:21:02 - INFO - __main__ -     eval_loss = 0.8535
07/31/2023 20:21:02 - INFO - __main__ -     eval_acc = 0.6047
07/31/2023 20:21:02 - INFO - __main__ -     ********************
07/31/2023 20:21:02 - INFO - __main__ -     Best acc:0.6047
07/31/2023 20:21:02 - INFO - __main__ -     ********************
07/31/2023 20:21:03 - INFO - __main__ -   Saving model checkpoint to ./saved_models/devign/checkpoint-best-acc/model.bin
07/31/2023 20:21:03 - INFO - __main__ -   epoch 7 loss 0.45981
07/31/2023 20:35:00 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 20:35:00 - INFO - __main__ -     Num examples = 2732
07/31/2023 20:35:00 - INFO - __main__ -     Batch size = 128
07/31/2023 20:35:32 - INFO - __main__ -     eval_loss = 0.9333
07/31/2023 20:35:32 - INFO - __main__ -     eval_acc = 0.5655
07/31/2023 20:35:32 - INFO - __main__ -   epoch 8 loss 0.38174
07/31/2023 20:45:07 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 20:45:07 - INFO - __main__ -     Num examples = 2732
07/31/2023 20:45:07 - INFO - __main__ -     Batch size = 128
07/31/2023 20:45:38 - INFO - __main__ -     eval_loss = 0.9207
07/31/2023 20:45:38 - INFO - __main__ -     eval_acc = 0.5911
07/31/2023 20:45:38 - INFO - __main__ -   epoch 9 loss 0.30945
07/31/2023 20:59:32 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 20:59:32 - INFO - __main__ -     Num examples = 2732
07/31/2023 20:59:32 - INFO - __main__ -     Batch size = 128
07/31/2023 21:00:00 - INFO - __main__ -     eval_loss = 1.1351
07/31/2023 21:00:00 - INFO - __main__ -     eval_acc = 0.5776
07/31/2023 21:00:00 - INFO - __main__ -   epoch 10 loss 0.29017
07/31/2023 21:13:55 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 21:13:55 - INFO - __main__ -     Num examples = 2732
07/31/2023 21:13:55 - INFO - __main__ -     Batch size = 128
07/31/2023 21:14:26 - INFO - __main__ -     eval_loss = 1.2808
07/31/2023 21:14:26 - INFO - __main__ -     eval_acc = 0.59
07/31/2023 21:14:26 - INFO - __main__ -   epoch 11 loss 0.22582
07/31/2023 21:28:23 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 21:28:23 - INFO - __main__ -     Num examples = 2732
07/31/2023 21:28:23 - INFO - __main__ -     Batch size = 128
07/31/2023 21:28:55 - INFO - __main__ -     eval_loss = 1.0145
07/31/2023 21:28:55 - INFO - __main__ -     eval_acc = 0.5952
07/31/2023 21:28:55 - INFO - __main__ -   epoch 12 loss 0.19606
07/31/2023 21:42:52 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 21:42:52 - INFO - __main__ -     Num examples = 2732
07/31/2023 21:42:52 - INFO - __main__ -     Batch size = 128
07/31/2023 21:43:24 - INFO - __main__ -     eval_loss = 1.4365
07/31/2023 21:43:24 - INFO - __main__ -     eval_acc = 0.5706
07/31/2023 21:43:24 - INFO - __main__ -   epoch 13 loss 0.17463
07/31/2023 21:57:17 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 21:57:17 - INFO - __main__ -     Num examples = 2732
07/31/2023 21:57:17 - INFO - __main__ -     Batch size = 128
07/31/2023 21:57:45 - INFO - __main__ -     eval_loss = 1.3288
07/31/2023 21:57:45 - INFO - __main__ -     eval_acc = 0.5794
07/31/2023 21:57:46 - INFO - __main__ -   epoch 14 loss 0.15371
07/31/2023 22:07:46 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 22:07:46 - INFO - __main__ -     Num examples = 2732
07/31/2023 22:07:46 - INFO - __main__ -     Batch size = 128
07/31/2023 22:08:50 - INFO - __main__ -     eval_loss = 1.4739
07/31/2023 22:08:50 - INFO - __main__ -     eval_acc = 0.6003
07/31/2023 22:08:50 - INFO - __main__ -   epoch 15 loss 0.14106
07/31/2023 22:22:42 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 22:22:42 - INFO - __main__ -     Num examples = 2732
07/31/2023 22:22:42 - INFO - __main__ -     Batch size = 128
07/31/2023 22:23:10 - INFO - __main__ -     eval_loss = 1.1464
07/31/2023 22:23:10 - INFO - __main__ -     eval_acc = 0.5721
07/31/2023 22:23:10 - INFO - __main__ -   epoch 16 loss 0.12374
07/31/2023 22:37:00 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 22:37:00 - INFO - __main__ -     Num examples = 2732
07/31/2023 22:37:00 - INFO - __main__ -     Batch size = 128
07/31/2023 22:38:17 - INFO - __main__ -     eval_loss = 1.4374
07/31/2023 22:38:17 - INFO - __main__ -     eval_acc = 0.5732
07/31/2023 22:38:17 - INFO - __main__ -   epoch 17 loss 0.11445
07/31/2023 22:52:06 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 22:52:06 - INFO - __main__ -     Num examples = 2732
07/31/2023 22:52:06 - INFO - __main__ -     Batch size = 128
07/31/2023 22:52:35 - INFO - __main__ -     eval_loss = 1.717
07/31/2023 22:52:35 - INFO - __main__ -     eval_acc = 0.5948
07/31/2023 22:52:35 - INFO - __main__ -   epoch 18 loss 0.10723
07/31/2023 23:06:29 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 23:06:29 - INFO - __main__ -     Num examples = 2732
07/31/2023 23:06:29 - INFO - __main__ -     Batch size = 128
07/31/2023 23:07:02 - INFO - __main__ -     eval_loss = 1.211
07/31/2023 23:07:02 - INFO - __main__ -     eval_acc = 0.5875
07/31/2023 23:07:02 - INFO - __main__ -   epoch 19 loss 0.09838
07/31/2023 23:20:54 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 23:20:54 - INFO - __main__ -     Num examples = 2732
07/31/2023 23:20:54 - INFO - __main__ -     Batch size = 128
07/31/2023 23:21:22 - INFO - __main__ -     eval_loss = 1.8963
07/31/2023 23:21:22 - INFO - __main__ -     eval_acc = 0.5728
07/31/2023 23:21:22 - INFO - __main__ -   epoch 20 loss 0.0956
07/31/2023 23:35:17 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 23:35:17 - INFO - __main__ -     Num examples = 2732
07/31/2023 23:35:17 - INFO - __main__ -     Batch size = 128
07/31/2023 23:36:33 - INFO - __main__ -     eval_loss = 1.4606
07/31/2023 23:36:33 - INFO - __main__ -     eval_acc = 0.5846
07/31/2023 23:36:33 - INFO - __main__ -   epoch 21 loss 0.09088
07/31/2023 23:50:26 - INFO - __main__ -   ***** Running evaluation *****
07/31/2023 23:50:26 - INFO - __main__ -     Num examples = 2732
07/31/2023 23:50:26 - INFO - __main__ -     Batch size = 128
07/31/2023 23:50:58 - INFO - __main__ -     eval_loss = 1.3861
07/31/2023 23:50:58 - INFO - __main__ -     eval_acc = 0.5725
07/31/2023 23:50:58 - INFO - __main__ -   epoch 22 loss 0.0799
08/01/2023 00:04:49 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 00:04:49 - INFO - __main__ -     Num examples = 2732
08/01/2023 00:04:49 - INFO - __main__ -     Batch size = 128
08/01/2023 00:05:17 - INFO - __main__ -     eval_loss = 1.5577
08/01/2023 00:05:17 - INFO - __main__ -     eval_acc = 0.582
08/01/2023 00:05:17 - INFO - __main__ -   epoch 23 loss 0.07909
08/01/2023 00:19:08 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 00:19:08 - INFO - __main__ -     Num examples = 2732
08/01/2023 00:19:08 - INFO - __main__ -     Batch size = 128
08/01/2023 00:20:25 - INFO - __main__ -     eval_loss = 1.9719
08/01/2023 00:20:25 - INFO - __main__ -     eval_acc = 0.5805
08/01/2023 00:20:25 - INFO - __main__ -   epoch 24 loss 0.07698
08/01/2023 00:34:17 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 00:34:17 - INFO - __main__ -     Num examples = 2732
08/01/2023 00:34:17 - INFO - __main__ -     Batch size = 128
08/01/2023 00:34:45 - INFO - __main__ -     eval_loss = 1.2226
08/01/2023 00:34:45 - INFO - __main__ -     eval_acc = 0.5794
08/01/2023 00:34:45 - INFO - __main__ -   epoch 25 loss 0.07018
08/01/2023 00:48:42 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 00:48:42 - INFO - __main__ -     Num examples = 2732
08/01/2023 00:48:42 - INFO - __main__ -     Batch size = 128
08/01/2023 00:49:58 - INFO - __main__ -     eval_loss = 1.6318
08/01/2023 00:49:58 - INFO - __main__ -     eval_acc = 0.5882
08/01/2023 00:49:58 - INFO - __main__ -   epoch 26 loss 0.06656
08/01/2023 01:03:54 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 01:03:54 - INFO - __main__ -     Num examples = 2732
08/01/2023 01:03:54 - INFO - __main__ -     Batch size = 128
08/01/2023 01:04:22 - INFO - __main__ -     eval_loss = 1.3665
08/01/2023 01:04:22 - INFO - __main__ -     eval_acc = 0.5853
08/01/2023 01:04:22 - INFO - __main__ -   epoch 27 loss 0.06531
08/01/2023 01:18:20 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 01:18:20 - INFO - __main__ -     Num examples = 2732
08/01/2023 01:18:20 - INFO - __main__ -     Batch size = 128
08/01/2023 01:19:36 - INFO - __main__ -     eval_loss = 1.6505
08/01/2023 01:19:36 - INFO - __main__ -     eval_acc = 0.5831
08/01/2023 01:19:36 - INFO - __main__ -   epoch 28 loss 0.06242
08/01/2023 01:33:29 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 01:33:29 - INFO - __main__ -     Num examples = 2732
08/01/2023 01:33:29 - INFO - __main__ -     Batch size = 128
08/01/2023 01:34:01 - INFO - __main__ -     eval_loss = 1.4493
08/01/2023 01:34:01 - INFO - __main__ -     eval_acc = 0.5911
08/01/2023 01:34:01 - INFO - __main__ -   epoch 29 loss 0.06024
08/01/2023 01:48:00 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 01:48:00 - INFO - __main__ -     Num examples = 2732
08/01/2023 01:48:00 - INFO - __main__ -     Batch size = 128
08/01/2023 01:48:32 - INFO - __main__ -     eval_loss = 1.1727
08/01/2023 01:48:32 - INFO - __main__ -     eval_acc = 0.5904
08/01/2023 01:48:32 - INFO - __main__ -   epoch 30 loss 0.05709
08/01/2023 02:02:27 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 02:02:27 - INFO - __main__ -     Num examples = 2732
08/01/2023 02:02:27 - INFO - __main__ -     Batch size = 128
08/01/2023 02:03:43 - INFO - __main__ -     eval_loss = 1.5271
08/01/2023 02:03:43 - INFO - __main__ -     eval_acc = 0.5798
08/01/2023 02:03:43 - INFO - __main__ -   epoch 31 loss 0.05584
08/01/2023 02:17:37 - INFO - __main__ -   ***** Running evaluation *****
08/01/2023 02:17:37 - INFO - __main__ -     Num examples = 2732
08/01/2023 02:17:37 - INFO - __main__ -     Batch size = 128
08/01/2023 02:18:53 - INFO - __main__ -     eval_loss = 1.5501
08/01/2023 02:18:53 - INFO - __main__ -     eval_acc = 0.5695
08/01/2023 02:18:53 - INFO - __main__ -   epoch 32 loss 0.05425